{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "DATA_PATH = '../data/'\n",
    "OUTPUT_PATH = '../output_data/'\n",
    "MODEL_PATH = '../data/models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_rows', 100)\n",
    "#pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index, Filename\n",
      "[(0, 'deepfake_txt.csv'), (1, 'results.csv'), (2, 'arxiv_disinformation.csv'), (3, 'arxiv_deepfake.csv')]\n"
     ]
    }
   ],
   "source": [
    "# Check files in data folder\n",
    "datafiles = [f for f in listdir(DATA_PATH) if isfile(join(DATA_PATH, f))]\n",
    "\n",
    "print('Index, Filename')\n",
    "print(list(zip([index for index, value in enumerate(datafiles)], datafiles)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'results.csv'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a file name, can use\n",
    "load_file = datafiles[1]\n",
    "load_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataframe\n",
    "CONVERTERS = {'tokens': eval, 'published_parsed': eval, 'tags': eval, 'arxiv_primary_category': eval}\n",
    "\n",
    "df = pd.read_csv(DATA_PATH + load_file, converters=CONVERTERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>guidislink</th>\n",
       "      <th>link</th>\n",
       "      <th>updated</th>\n",
       "      <th>updated_parsed</th>\n",
       "      <th>published</th>\n",
       "      <th>published_parsed</th>\n",
       "      <th>title</th>\n",
       "      <th>title_detail</th>\n",
       "      <th>summary</th>\n",
       "      <th>...</th>\n",
       "      <th>author_detail</th>\n",
       "      <th>author</th>\n",
       "      <th>links</th>\n",
       "      <th>arxiv_primary_category</th>\n",
       "      <th>tags</th>\n",
       "      <th>arxiv_comment</th>\n",
       "      <th>arxiv_doi</th>\n",
       "      <th>arxiv_journal_ref</th>\n",
       "      <th>search_term</th>\n",
       "      <th>arxiv_affiliation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://arxiv.org/abs/2204.02960v1</td>\n",
       "      <td>True</td>\n",
       "      <td>http://arxiv.org/abs/2204.02960v1</td>\n",
       "      <td>2022-04-06T17:54:46Z</td>\n",
       "      <td>[2022, 4, 6, 17, 54, 46, 2, 96, 0]</td>\n",
       "      <td>2022-04-06T17:54:46Z</td>\n",
       "      <td>[2022, 4, 6, 17, 54, 46, 2, 96, 0]</td>\n",
       "      <td>Simple and Effective Synthesis of Indoor 3D Sc...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>We study the problem of synthesizing immersive...</td>\n",
       "      <td>...</td>\n",
       "      <td>{'name': 'Peter Anderson'}</td>\n",
       "      <td>Peter Anderson</td>\n",
       "      <td>[{'href': 'http://arxiv.org/abs/2204.02960v1',...</td>\n",
       "      <td>{'term': 'cs.CV', 'scheme': 'http://arxiv.org/...</td>\n",
       "      <td>[{'term': 'cs.CV', 'scheme': 'http://arxiv.org...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GAN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://arxiv.org/abs/2204.02591v1</td>\n",
       "      <td>True</td>\n",
       "      <td>http://arxiv.org/abs/2204.02591v1</td>\n",
       "      <td>2022-04-06T05:51:04Z</td>\n",
       "      <td>[2022, 4, 6, 5, 51, 4, 2, 96, 0]</td>\n",
       "      <td>2022-04-06T05:51:04Z</td>\n",
       "      <td>[2022, 4, 6, 5, 51, 4, 2, 96, 0]</td>\n",
       "      <td>Contextual Attention Mechanism, SRGAN Based In...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>The new alternative is to use deep learning to...</td>\n",
       "      <td>...</td>\n",
       "      <td>{'name': 'Anwesh Reddy Paduri'}</td>\n",
       "      <td>Anwesh Reddy Paduri</td>\n",
       "      <td>[{'href': 'http://arxiv.org/abs/2204.02591v1',...</td>\n",
       "      <td>{'term': 'cs.CV', 'scheme': 'http://arxiv.org/...</td>\n",
       "      <td>[{'term': 'cs.CV', 'scheme': 'http://arxiv.org...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GAN, fake news</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  id  guidislink  \\\n",
       "0  http://arxiv.org/abs/2204.02960v1        True   \n",
       "1  http://arxiv.org/abs/2204.02591v1        True   \n",
       "\n",
       "                                link               updated  \\\n",
       "0  http://arxiv.org/abs/2204.02960v1  2022-04-06T17:54:46Z   \n",
       "1  http://arxiv.org/abs/2204.02591v1  2022-04-06T05:51:04Z   \n",
       "\n",
       "                       updated_parsed             published  \\\n",
       "0  [2022, 4, 6, 17, 54, 46, 2, 96, 0]  2022-04-06T17:54:46Z   \n",
       "1    [2022, 4, 6, 5, 51, 4, 2, 96, 0]  2022-04-06T05:51:04Z   \n",
       "\n",
       "                     published_parsed  \\\n",
       "0  [2022, 4, 6, 17, 54, 46, 2, 96, 0]   \n",
       "1    [2022, 4, 6, 5, 51, 4, 2, 96, 0]   \n",
       "\n",
       "                                               title  \\\n",
       "0  Simple and Effective Synthesis of Indoor 3D Sc...   \n",
       "1  Contextual Attention Mechanism, SRGAN Based In...   \n",
       "\n",
       "                                        title_detail  \\\n",
       "0  {'type': 'text/plain', 'language': None, 'base...   \n",
       "1  {'type': 'text/plain', 'language': None, 'base...   \n",
       "\n",
       "                                             summary  ...  \\\n",
       "0  We study the problem of synthesizing immersive...  ...   \n",
       "1  The new alternative is to use deep learning to...  ...   \n",
       "\n",
       "                     author_detail               author  \\\n",
       "0       {'name': 'Peter Anderson'}       Peter Anderson   \n",
       "1  {'name': 'Anwesh Reddy Paduri'}  Anwesh Reddy Paduri   \n",
       "\n",
       "                                               links  \\\n",
       "0  [{'href': 'http://arxiv.org/abs/2204.02960v1',...   \n",
       "1  [{'href': 'http://arxiv.org/abs/2204.02591v1',...   \n",
       "\n",
       "                              arxiv_primary_category  \\\n",
       "0  {'term': 'cs.CV', 'scheme': 'http://arxiv.org/...   \n",
       "1  {'term': 'cs.CV', 'scheme': 'http://arxiv.org/...   \n",
       "\n",
       "                                                tags arxiv_comment arxiv_doi  \\\n",
       "0  [{'term': 'cs.CV', 'scheme': 'http://arxiv.org...           NaN       NaN   \n",
       "1  [{'term': 'cs.CV', 'scheme': 'http://arxiv.org...           NaN       NaN   \n",
       "\n",
       "  arxiv_journal_ref     search_term arxiv_affiliation  \n",
       "0               NaN             GAN               NaN  \n",
       "1               NaN  GAN, fake news               NaN  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "399"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.published_parsed.max())\n",
    "print(df.published_parsed.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.arxiv_primary_category[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tags[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tags\n",
    "\n",
    "tag_list = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "      tag = row.tags[0]['term']\n",
    "      tag_list.append(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(tag_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTES - MOVED TO PROCESSING - delete once sure there are no dependencies\n",
    "def get_tag(x):\n",
    "      tag = x[0]['term']\n",
    "      # TO DO - scrape https://arxiv.org/category_taxonomy to translate codes to plain english\n",
    "      return tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTES - MOVED TO PROCESSING - delete once sure there are no dependencies\n",
    "\n",
    "df['category'] = df['tags'].dropna().apply(lambda x:  get_tag(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding some data \n",
    "Only needs to be done once but retaining code for new collections\n",
    "\n",
    "Could move to preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTES - MOVED TO PROCESSING - delete once sure there are no dependencies\n",
    "\n",
    "def get_period(x, period):\n",
    "      #output = x.split(',')[period] ## For string splitting\n",
    "      output = x[:period]\n",
    "      if len(output) == 1:\n",
    "            return output[0]\n",
    "      else:\n",
    "            return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTES - MOVED TO PROCESSING - delete once sure there are no dependencies\n",
    "\n",
    "df['year'] = df['published_parsed'].dropna().apply(lambda x:  get_period(x, 1))\n",
    "df['month_year'] = df['published_parsed'].dropna().apply(lambda x:  get_period(x, 2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.year.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Closing out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = load_file.split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH + out_file + '.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(DATA_PATH + out_file + '.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f045682951559cbc0979d5d7223b93f289f756c5241efdcb485f4eca938569a1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 ('dri_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
