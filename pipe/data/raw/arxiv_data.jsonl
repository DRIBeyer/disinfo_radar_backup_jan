{"id": "http://arxiv.org/abs/2205.15659v2", "guidislink": true, "link": "http://arxiv.org/abs/2205.15659v2", "updated": "2022-06-04T14:42:42Z", "updated_parsed": [2022, 6, 4, 14, 42, 42, 5, 155, 0], "published": "2022-05-31T09:56:44Z", "published_parsed": [2022, 5, 31, 9, 56, 44, 1, 151, 0], "title": "The CLRS Algorithmic Reasoning Benchmark", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=DeepMind&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=3", "value": "The CLRS Algorithmic Reasoning Benchmark"}, "summary": "Learning representations of algorithms is an emerging area of machine\nlearning, seeking to bridge concepts from neural networks with classical\nalgorithms. Several important works have investigated whether neural networks\ncan effectively reason like algorithms, typically by learning to execute them.\nThe common trend in the area, however, is to generate targeted kinds of\nalgorithmic data to evaluate specific hypotheses, making results hard to\ntransfer across publications, and increasing the barrier of entry. To\nconsolidate progress and work towards unified evaluation, we propose the CLRS\nAlgorithmic Reasoning Benchmark, covering classical algorithms from the\nIntroduction to Algorithms textbook. Our benchmark spans a variety of\nalgorithmic reasoning procedures, including sorting, searching, dynamic\nprogramming, graph algorithms, string algorithms and geometric algorithms. We\nperform extensive experiments to demonstrate how several popular algorithmic\nreasoning baselines perform on these tasks, and consequently, highlight links\nto several open challenges. Our library is readily available at\nhttps://github.com/deepmind/clrs.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=DeepMind&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=3", "value": "Learning representations of algorithms is an emerging area of machine\nlearning, seeking to bridge concepts from neural networks with classical\nalgorithms. Several important works have investigated whether neural networks\ncan effectively reason like algorithms, typically by learning to execute them.\nThe common trend in the area, however, is to generate targeted kinds of\nalgorithmic data to evaluate specific hypotheses, making results hard to\ntransfer across publications, and increasing the barrier of entry. To\nconsolidate progress and work towards unified evaluation, we propose the CLRS\nAlgorithmic Reasoning Benchmark, covering classical algorithms from the\nIntroduction to Algorithms textbook. Our benchmark spans a variety of\nalgorithmic reasoning procedures, including sorting, searching, dynamic\nprogramming, graph algorithms, string algorithms and geometric algorithms. We\nperform extensive experiments to demonstrate how several popular algorithmic\nreasoning baselines perform on these tasks, and consequently, highlight links\nto several open challenges. Our library is readily available at\nhttps://github.com/deepmind/clrs."}, "authors": [{"name": "Petar Veli\u010dkovi\u0107"}, {"name": "Adri\u00e0 Puigdom\u00e8nech Badia"}, {"name": "David Budden"}, {"name": "Razvan Pascanu"}, {"name": "Andrea Banino"}, {"name": "Misha Dashevskiy"}, {"name": "Raia Hadsell"}, {"name": "Charles Blundell"}], "author_detail": {"name": "Charles Blundell"}, "author": "Charles Blundell", "arxiv_comment": "To appear in ICML 2022. 19 pages, 4 figures", "links": [{"href": "http://arxiv.org/abs/2205.15659v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2205.15659v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.DS", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "stat.ML", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}
{"id": "http://arxiv.org/abs/2205.13521v1", "guidislink": true, "link": "http://arxiv.org/abs/2205.13521v1", "updated": "2022-05-26T17:40:52Z", "updated_parsed": [2022, 5, 26, 17, 40, 52, 3, 146, 0], "published": "2022-05-26T17:40:52Z", "published_parsed": [2022, 5, 26, 17, 40, 52, 3, 146, 0], "title": "Discovering Policies with DOMiNO: Diversity Optimization Maintaining\n  Near Optimality", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=DeepMind&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=3", "value": "Discovering Policies with DOMiNO: Diversity Optimization Maintaining\n  Near Optimality"}, "summary": "Finding different solutions to the same problem is a key aspect of\nintelligence associated with creativity and adaptation to novel situations. In\nreinforcement learning, a set of diverse policies can be useful for\nexploration, transfer, hierarchy, and robustness. We propose DOMiNO, a method\nfor Diversity Optimization Maintaining Near Optimality. We formalize the\nproblem as a Constrained Markov Decision Process where the objective is to find\ndiverse policies, measured by the distance between the state occupancies of the\npolicies in the set, while remaining near-optimal with respect to the extrinsic\nreward. We demonstrate that the method can discover diverse and meaningful\nbehaviors in various domains, such as different locomotion patterns in the\nDeepMind Control Suite. We perform extensive analysis of our approach, compare\nit with other multi-objective baselines, demonstrate that we can control both\nthe quality and the diversity of the set via interpretable hyperparameters, and\nshow that the discovered set is robust to perturbations.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=DeepMind&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=3", "value": "Finding different solutions to the same problem is a key aspect of\nintelligence associated with creativity and adaptation to novel situations. In\nreinforcement learning, a set of diverse policies can be useful for\nexploration, transfer, hierarchy, and robustness. We propose DOMiNO, a method\nfor Diversity Optimization Maintaining Near Optimality. We formalize the\nproblem as a Constrained Markov Decision Process where the objective is to find\ndiverse policies, measured by the distance between the state occupancies of the\npolicies in the set, while remaining near-optimal with respect to the extrinsic\nreward. We demonstrate that the method can discover diverse and meaningful\nbehaviors in various domains, such as different locomotion patterns in the\nDeepMind Control Suite. We perform extensive analysis of our approach, compare\nit with other multi-objective baselines, demonstrate that we can control both\nthe quality and the diversity of the set via interpretable hyperparameters, and\nshow that the discovered set is robust to perturbations."}, "authors": [{"name": "Tom Zahavy"}, {"name": "Yannick Schroecker"}, {"name": "Feryal Behbahani"}, {"name": "Kate Baumli"}, {"name": "Sebastian Flennerhag"}, {"name": "Shaobo Hou"}, {"name": "Satinder Singh"}], "author_detail": {"name": "Satinder Singh"}, "author": "Satinder Singh", "links": [{"href": "http://arxiv.org/abs/2205.13521v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2205.13521v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}
{"id": "http://arxiv.org/abs/2205.10218v2", "guidislink": true, "link": "http://arxiv.org/abs/2205.10218v2", "updated": "2022-06-09T13:21:47Z", "updated_parsed": [2022, 6, 9, 13, 21, 47, 3, 160, 0], "published": "2022-05-20T14:52:03Z", "published_parsed": [2022, 5, 20, 14, 52, 3, 4, 140, 0], "title": "Learning Task-relevant Representations for Generalization via\n  Characteristic Functions of Reward Sequence Distributions", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=DeepMind&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=3", "value": "Learning Task-relevant Representations for Generalization via\n  Characteristic Functions of Reward Sequence Distributions"}, "summary": "Generalization across different environments with the same tasks is critical\nfor successful applications of visual reinforcement learning (RL) in real\nscenarios. However, visual distractions -- which are common in real scenes --\nfrom high-dimensional observations can be hurtful to the learned\nrepresentations in visual RL, thus degrading the performance of generalization.\nTo tackle this problem, we propose a novel approach, namely Characteristic\nReward Sequence Prediction (CRESP), to extract the task-relevant information by\nlearning reward sequence distributions (RSDs), as the reward signals are\ntask-relevant in RL and invariant to visual distractions. Specifically, to\neffectively capture the task-relevant information via RSDs, CRESP introduces an\nauxiliary task -- that is, predicting the characteristic functions of RSDs --\nto learn task-relevant representations, because we can well approximate the\nhigh-dimensional distributions by leveraging the corresponding characteristic\nfunctions. Experiments demonstrate that CRESP significantly improves the\nperformance of generalization on unseen environments, outperforming several\nstate-of-the-arts on DeepMind Control tasks with different visual distractions.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=DeepMind&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=3", "value": "Generalization across different environments with the same tasks is critical\nfor successful applications of visual reinforcement learning (RL) in real\nscenarios. However, visual distractions -- which are common in real scenes --\nfrom high-dimensional observations can be hurtful to the learned\nrepresentations in visual RL, thus degrading the performance of generalization.\nTo tackle this problem, we propose a novel approach, namely Characteristic\nReward Sequence Prediction (CRESP), to extract the task-relevant information by\nlearning reward sequence distributions (RSDs), as the reward signals are\ntask-relevant in RL and invariant to visual distractions. Specifically, to\neffectively capture the task-relevant information via RSDs, CRESP introduces an\nauxiliary task -- that is, predicting the characteristic functions of RSDs --\nto learn task-relevant representations, because we can well approximate the\nhigh-dimensional distributions by leveraging the corresponding characteristic\nfunctions. Experiments demonstrate that CRESP significantly improves the\nperformance of generalization on unseen environments, outperforming several\nstate-of-the-arts on DeepMind Control tasks with different visual distractions."}, "authors": [{"name": "Rui Yang"}, {"name": "Jie Wang"}, {"name": "Zijie Geng"}, {"name": "Mingxuan Ye"}, {"name": "Shuiwang Ji"}, {"name": "Bin Li"}, {"name": "Feng Wu"}], "author_detail": {"name": "Feng Wu"}, "author": "Feng Wu", "arxiv_doi": "10.1145/3534678.3539391", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1145/3534678.3539391", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/2205.10218v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2205.10218v2", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "Accepted to KDD 2022", "arxiv_primary_category": {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}
{"id": "http://arxiv.org/abs/2206.06706v1", "guidislink": true, "link": "http://arxiv.org/abs/2206.06706v1", "updated": "2022-06-14T09:12:48Z", "updated_parsed": [2022, 6, 14, 9, 12, 48, 1, 165, 0], "published": "2022-06-14T09:12:48Z", "published_parsed": [2022, 6, 14, 9, 12, 48, 1, 165, 0], "title": "An analysis of retracted papers in Computer Science", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=Google&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=3", "value": "An analysis of retracted papers in Computer Science"}, "summary": "Context: The retraction of research papers, for whatever reason, is a growing\nphenomenon. However, although retracted paper information is publicly available\nvia publishers, it is somewhat distributed and inconsistent. Objective: The aim\nis to assess: (i) the extent and nature of retracted research in Computer\nScience (CS) (ii) the post-retraction citation behaviour of retracted works and\n(iii) the potential impact on systematic reviews and mapping studies. Method:\nWe analyse the Retraction Watch database and take citation information from the\nWeb of Science and Google scholar. Results: We find that of the 33,955 entries\nin the Retraction watch database (16 May 2022), 2,816 are classified as CS,\ni.e., approximately 8.3%. For CS, 56% of retracted papers, provide little or no\ninformation as to the reasons. This contrasts with 26% for other disciplines.\nThere is also a remarkable disparity between different publishers, a tendency\nfor multiple versions of a retracted paper over and above the Version of Record\n(VoR), and for new citations long after a paper is officially retracted.\nConclusions: Unfortunately retraction seems to be a sufficiently common outcome\nfor a scientific paper that we as a research community need to take it more\nseriously, e.g., standardising procedures and taxonomies across publishers and\nthe provision of appropriate research tools. Finally, we recommend particular\ncaution when undertaking secondary analyses and meta-analyses which are at risk\nof becoming contaminated by these problem primary studies.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=Google&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=3", "value": "Context: The retraction of research papers, for whatever reason, is a growing\nphenomenon. However, although retracted paper information is publicly available\nvia publishers, it is somewhat distributed and inconsistent. Objective: The aim\nis to assess: (i) the extent and nature of retracted research in Computer\nScience (CS) (ii) the post-retraction citation behaviour of retracted works and\n(iii) the potential impact on systematic reviews and mapping studies. Method:\nWe analyse the Retraction Watch database and take citation information from the\nWeb of Science and Google scholar. Results: We find that of the 33,955 entries\nin the Retraction watch database (16 May 2022), 2,816 are classified as CS,\ni.e., approximately 8.3%. For CS, 56% of retracted papers, provide little or no\ninformation as to the reasons. This contrasts with 26% for other disciplines.\nThere is also a remarkable disparity between different publishers, a tendency\nfor multiple versions of a retracted paper over and above the Version of Record\n(VoR), and for new citations long after a paper is officially retracted.\nConclusions: Unfortunately retraction seems to be a sufficiently common outcome\nfor a scientific paper that we as a research community need to take it more\nseriously, e.g., standardising procedures and taxonomies across publishers and\nthe provision of appropriate research tools. Finally, we recommend particular\ncaution when undertaking secondary analyses and meta-analyses which are at risk\nof becoming contaminated by these problem primary studies."}, "authors": [{"name": "Martin Shepperd"}, {"name": "Leila Yousefi"}], "author_detail": {"name": "Leila Yousefi"}, "author": "Leila Yousefi", "arxiv_comment": "This is a preprint of the paper submitted to PLOS ONE", "links": [{"href": "http://arxiv.org/abs/2206.06706v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2206.06706v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.DL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.DL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.IR", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}
{"id": "http://arxiv.org/abs/2206.06490v1", "guidislink": true, "link": "http://arxiv.org/abs/2206.06490v1", "updated": "2022-06-13T21:37:58Z", "updated_parsed": [2022, 6, 13, 21, 37, 58, 0, 164, 0], "published": "2022-06-13T21:37:58Z", "published_parsed": [2022, 6, 13, 21, 37, 58, 0, 164, 0], "title": "Learning Task-Independent Game State Representations from Unlabeled\n  Images", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=Google&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=3", "value": "Learning Task-Independent Game State Representations from Unlabeled\n  Images"}, "summary": "Self-supervised learning (SSL) techniques have been widely used to learn\ncompact and informative representations from high-dimensional complex data. In\nmany computer vision tasks, such as image classification, such methods achieve\nstate-of-the-art results that surpass supervised learning approaches. In this\npaper, we investigate whether SSL methods can be leveraged for the task of\nlearning accurate state representations of games, and if so, to what extent.\nFor this purpose, we collect game footage frames and corresponding sequences of\ngames' internal state from three different 3D games: VizDoom, the CARLA racing\nsimulator and the Google Research Football Environment. We train an image\nencoder with three widely used SSL algorithms using solely the raw frames, and\nthen attempt to recover the internal state variables from the learned\nrepresentations. Our results across all three games showcase significantly\nhigher correlation between SSL representations and the game's internal state\ncompared to pre-trained baseline models such as ImageNet. Such findings suggest\nthat SSL-based visual encoders can yield general -- not tailored to a specific\ntask -- yet informative game representations solely from game pixel\ninformation. Such representations can, in turn, form the basis for boosting the\nperformance of downstream learning tasks in games, including gameplaying,\ncontent generation and player modeling.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=Google&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=3", "value": "Self-supervised learning (SSL) techniques have been widely used to learn\ncompact and informative representations from high-dimensional complex data. In\nmany computer vision tasks, such as image classification, such methods achieve\nstate-of-the-art results that surpass supervised learning approaches. In this\npaper, we investigate whether SSL methods can be leveraged for the task of\nlearning accurate state representations of games, and if so, to what extent.\nFor this purpose, we collect game footage frames and corresponding sequences of\ngames' internal state from three different 3D games: VizDoom, the CARLA racing\nsimulator and the Google Research Football Environment. We train an image\nencoder with three widely used SSL algorithms using solely the raw frames, and\nthen attempt to recover the internal state variables from the learned\nrepresentations. Our results across all three games showcase significantly\nhigher correlation between SSL representations and the game's internal state\ncompared to pre-trained baseline models such as ImageNet. Such findings suggest\nthat SSL-based visual encoders can yield general -- not tailored to a specific\ntask -- yet informative game representations solely from game pixel\ninformation. Such representations can, in turn, form the basis for boosting the\nperformance of downstream learning tasks in games, including gameplaying,\ncontent generation and player modeling."}, "authors": [{"name": "Chintan Trivedi"}, {"name": "Konstantinos Makantasis"}, {"name": "Antonios Liapis"}, {"name": "Georgios N. Yannakakis"}], "author_detail": {"name": "Georgios N. Yannakakis"}, "author": "Georgios N. Yannakakis", "arxiv_comment": "Conference on Games (CoG) 2022", "links": [{"href": "http://arxiv.org/abs/2206.06490v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2206.06490v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}
{"id": "http://arxiv.org/abs/2206.05146v1", "guidislink": true, "link": "http://arxiv.org/abs/2206.05146v1", "updated": "2022-06-10T14:39:59Z", "updated_parsed": [2022, 6, 10, 14, 39, 59, 4, 161, 0], "published": "2022-06-10T14:39:59Z", "published_parsed": [2022, 6, 10, 14, 39, 59, 4, 161, 0], "title": "Global Internet public peering capacity of interconnection: a complex\n  network analysis", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=Google&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=3", "value": "Global Internet public peering capacity of interconnection: a complex\n  network analysis"}, "summary": "A massive and growing part of Autonomous System (AS)-level traffic exchanges\ntakes place at Internet Exchange Points (IXPs). This paper leverages PeeringDB,\na database providing a partial but reasonable view of the global\ninterconnection of ASes at IXPs, to model a complex graph enabling the\ncharacterization of the key Internet peering players and their interactions\nover time. We model a PeeringDB snapshot as a weighted directed bipartite\ngraph, called the pDB c-graph, that captures the port size ASes possess at IXPs\nusing available metadata. This novel model of the Internet is shown to picture\nrelevant features of a complex network that groups ASes and IXPs in\ngeographical areas of influence. From this model, we extract central players of\npublic peering such as hypergiant AS content providers and major regional\ntraffic receivers. Most importantly, this graph model opens the way to apply\nspectral analysis using reduced Google matrix in order to retrieve the\nintensity of possible interactions between ASes on the basis of pure\nconnectivity information. As an illustration, we retrieve the timely evolution\nof the peering network to show how the central content and cloud providers have\nincreased their reach to eyeball networks during Covid-19 pandemic.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=Google&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=3", "value": "A massive and growing part of Autonomous System (AS)-level traffic exchanges\ntakes place at Internet Exchange Points (IXPs). This paper leverages PeeringDB,\na database providing a partial but reasonable view of the global\ninterconnection of ASes at IXPs, to model a complex graph enabling the\ncharacterization of the key Internet peering players and their interactions\nover time. We model a PeeringDB snapshot as a weighted directed bipartite\ngraph, called the pDB c-graph, that captures the port size ASes possess at IXPs\nusing available metadata. This novel model of the Internet is shown to picture\nrelevant features of a complex network that groups ASes and IXPs in\ngeographical areas of influence. From this model, we extract central players of\npublic peering such as hypergiant AS content providers and major regional\ntraffic receivers. Most importantly, this graph model opens the way to apply\nspectral analysis using reduced Google matrix in order to retrieve the\nintensity of possible interactions between ASes on the basis of pure\nconnectivity information. As an illustration, we retrieve the timely evolution\nof the peering network to show how the central content and cloud providers have\nincreased their reach to eyeball networks during Covid-19 pandemic."}, "authors": [{"name": "Justin Loye"}, {"name": "Sandrine Mouysset"}, {"name": "Marc Bruy\u00e8re"}, {"name": "Katia Jaffr\u00e8s-Runser"}], "author_detail": {"name": "Katia Jaffr\u00e8s-Runser"}, "author": "Katia Jaffr\u00e8s-Runser", "links": [{"href": "http://arxiv.org/abs/2206.05146v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2206.05146v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.NI", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.NI", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}
{"id": "http://arxiv.org/abs/2205.15659v2", "guidislink": true, "link": "http://arxiv.org/abs/2205.15659v2", "updated": "2022-06-04T14:42:42Z", "updated_parsed": [2022, 6, 4, 14, 42, 42, 5, 155, 0], "published": "2022-05-31T09:56:44Z", "published_parsed": [2022, 5, 31, 9, 56, 44, 1, 151, 0], "title": "The CLRS Algorithmic Reasoning Benchmark", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=DeepMind&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=2", "value": "The CLRS Algorithmic Reasoning Benchmark"}, "summary": "Learning representations of algorithms is an emerging area of machine\nlearning, seeking to bridge concepts from neural networks with classical\nalgorithms. Several important works have investigated whether neural networks\ncan effectively reason like algorithms, typically by learning to execute them.\nThe common trend in the area, however, is to generate targeted kinds of\nalgorithmic data to evaluate specific hypotheses, making results hard to\ntransfer across publications, and increasing the barrier of entry. To\nconsolidate progress and work towards unified evaluation, we propose the CLRS\nAlgorithmic Reasoning Benchmark, covering classical algorithms from the\nIntroduction to Algorithms textbook. Our benchmark spans a variety of\nalgorithmic reasoning procedures, including sorting, searching, dynamic\nprogramming, graph algorithms, string algorithms and geometric algorithms. We\nperform extensive experiments to demonstrate how several popular algorithmic\nreasoning baselines perform on these tasks, and consequently, highlight links\nto several open challenges. Our library is readily available at\nhttps://github.com/deepmind/clrs.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=DeepMind&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=2", "value": "Learning representations of algorithms is an emerging area of machine\nlearning, seeking to bridge concepts from neural networks with classical\nalgorithms. Several important works have investigated whether neural networks\ncan effectively reason like algorithms, typically by learning to execute them.\nThe common trend in the area, however, is to generate targeted kinds of\nalgorithmic data to evaluate specific hypotheses, making results hard to\ntransfer across publications, and increasing the barrier of entry. To\nconsolidate progress and work towards unified evaluation, we propose the CLRS\nAlgorithmic Reasoning Benchmark, covering classical algorithms from the\nIntroduction to Algorithms textbook. Our benchmark spans a variety of\nalgorithmic reasoning procedures, including sorting, searching, dynamic\nprogramming, graph algorithms, string algorithms and geometric algorithms. We\nperform extensive experiments to demonstrate how several popular algorithmic\nreasoning baselines perform on these tasks, and consequently, highlight links\nto several open challenges. Our library is readily available at\nhttps://github.com/deepmind/clrs."}, "authors": [{"name": "Petar Veli\u010dkovi\u0107"}, {"name": "Adri\u00e0 Puigdom\u00e8nech Badia"}, {"name": "David Budden"}, {"name": "Razvan Pascanu"}, {"name": "Andrea Banino"}, {"name": "Misha Dashevskiy"}, {"name": "Raia Hadsell"}, {"name": "Charles Blundell"}], "author_detail": {"name": "Charles Blundell"}, "author": "Charles Blundell", "arxiv_comment": "To appear in ICML 2022. 19 pages, 4 figures", "links": [{"href": "http://arxiv.org/abs/2205.15659v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2205.15659v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.DS", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "stat.ML", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}
{"id": "http://arxiv.org/abs/2205.13521v1", "guidislink": true, "link": "http://arxiv.org/abs/2205.13521v1", "updated": "2022-05-26T17:40:52Z", "updated_parsed": [2022, 5, 26, 17, 40, 52, 3, 146, 0], "published": "2022-05-26T17:40:52Z", "published_parsed": [2022, 5, 26, 17, 40, 52, 3, 146, 0], "title": "Discovering Policies with DOMiNO: Diversity Optimization Maintaining\n  Near Optimality", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=DeepMind&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=2", "value": "Discovering Policies with DOMiNO: Diversity Optimization Maintaining\n  Near Optimality"}, "summary": "Finding different solutions to the same problem is a key aspect of\nintelligence associated with creativity and adaptation to novel situations. In\nreinforcement learning, a set of diverse policies can be useful for\nexploration, transfer, hierarchy, and robustness. We propose DOMiNO, a method\nfor Diversity Optimization Maintaining Near Optimality. We formalize the\nproblem as a Constrained Markov Decision Process where the objective is to find\ndiverse policies, measured by the distance between the state occupancies of the\npolicies in the set, while remaining near-optimal with respect to the extrinsic\nreward. We demonstrate that the method can discover diverse and meaningful\nbehaviors in various domains, such as different locomotion patterns in the\nDeepMind Control Suite. We perform extensive analysis of our approach, compare\nit with other multi-objective baselines, demonstrate that we can control both\nthe quality and the diversity of the set via interpretable hyperparameters, and\nshow that the discovered set is robust to perturbations.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=DeepMind&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=2", "value": "Finding different solutions to the same problem is a key aspect of\nintelligence associated with creativity and adaptation to novel situations. In\nreinforcement learning, a set of diverse policies can be useful for\nexploration, transfer, hierarchy, and robustness. We propose DOMiNO, a method\nfor Diversity Optimization Maintaining Near Optimality. We formalize the\nproblem as a Constrained Markov Decision Process where the objective is to find\ndiverse policies, measured by the distance between the state occupancies of the\npolicies in the set, while remaining near-optimal with respect to the extrinsic\nreward. We demonstrate that the method can discover diverse and meaningful\nbehaviors in various domains, such as different locomotion patterns in the\nDeepMind Control Suite. We perform extensive analysis of our approach, compare\nit with other multi-objective baselines, demonstrate that we can control both\nthe quality and the diversity of the set via interpretable hyperparameters, and\nshow that the discovered set is robust to perturbations."}, "authors": [{"name": "Tom Zahavy"}, {"name": "Yannick Schroecker"}, {"name": "Feryal Behbahani"}, {"name": "Kate Baumli"}, {"name": "Sebastian Flennerhag"}, {"name": "Shaobo Hou"}, {"name": "Satinder Singh"}], "author_detail": {"name": "Satinder Singh"}, "author": "Satinder Singh", "links": [{"href": "http://arxiv.org/abs/2205.13521v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2205.13521v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}
{"id": "http://arxiv.org/abs/2206.06706v1", "guidislink": true, "link": "http://arxiv.org/abs/2206.06706v1", "updated": "2022-06-14T09:12:48Z", "updated_parsed": [2022, 6, 14, 9, 12, 48, 1, 165, 0], "published": "2022-06-14T09:12:48Z", "published_parsed": [2022, 6, 14, 9, 12, 48, 1, 165, 0], "title": "An analysis of retracted papers in Computer Science", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=Google&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=2", "value": "An analysis of retracted papers in Computer Science"}, "summary": "Context: The retraction of research papers, for whatever reason, is a growing\nphenomenon. However, although retracted paper information is publicly available\nvia publishers, it is somewhat distributed and inconsistent. Objective: The aim\nis to assess: (i) the extent and nature of retracted research in Computer\nScience (CS) (ii) the post-retraction citation behaviour of retracted works and\n(iii) the potential impact on systematic reviews and mapping studies. Method:\nWe analyse the Retraction Watch database and take citation information from the\nWeb of Science and Google scholar. Results: We find that of the 33,955 entries\nin the Retraction watch database (16 May 2022), 2,816 are classified as CS,\ni.e., approximately 8.3%. For CS, 56% of retracted papers, provide little or no\ninformation as to the reasons. This contrasts with 26% for other disciplines.\nThere is also a remarkable disparity between different publishers, a tendency\nfor multiple versions of a retracted paper over and above the Version of Record\n(VoR), and for new citations long after a paper is officially retracted.\nConclusions: Unfortunately retraction seems to be a sufficiently common outcome\nfor a scientific paper that we as a research community need to take it more\nseriously, e.g., standardising procedures and taxonomies across publishers and\nthe provision of appropriate research tools. Finally, we recommend particular\ncaution when undertaking secondary analyses and meta-analyses which are at risk\nof becoming contaminated by these problem primary studies.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=Google&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=2", "value": "Context: The retraction of research papers, for whatever reason, is a growing\nphenomenon. However, although retracted paper information is publicly available\nvia publishers, it is somewhat distributed and inconsistent. Objective: The aim\nis to assess: (i) the extent and nature of retracted research in Computer\nScience (CS) (ii) the post-retraction citation behaviour of retracted works and\n(iii) the potential impact on systematic reviews and mapping studies. Method:\nWe analyse the Retraction Watch database and take citation information from the\nWeb of Science and Google scholar. Results: We find that of the 33,955 entries\nin the Retraction watch database (16 May 2022), 2,816 are classified as CS,\ni.e., approximately 8.3%. For CS, 56% of retracted papers, provide little or no\ninformation as to the reasons. This contrasts with 26% for other disciplines.\nThere is also a remarkable disparity between different publishers, a tendency\nfor multiple versions of a retracted paper over and above the Version of Record\n(VoR), and for new citations long after a paper is officially retracted.\nConclusions: Unfortunately retraction seems to be a sufficiently common outcome\nfor a scientific paper that we as a research community need to take it more\nseriously, e.g., standardising procedures and taxonomies across publishers and\nthe provision of appropriate research tools. Finally, we recommend particular\ncaution when undertaking secondary analyses and meta-analyses which are at risk\nof becoming contaminated by these problem primary studies."}, "authors": [{"name": "Martin Shepperd"}, {"name": "Leila Yousefi"}], "author_detail": {"name": "Leila Yousefi"}, "author": "Leila Yousefi", "arxiv_comment": "This is a preprint of the paper submitted to PLOS ONE", "links": [{"href": "http://arxiv.org/abs/2206.06706v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2206.06706v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.DL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.DL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.IR", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}
{"id": "http://arxiv.org/abs/2206.06490v1", "guidislink": true, "link": "http://arxiv.org/abs/2206.06490v1", "updated": "2022-06-13T21:37:58Z", "updated_parsed": [2022, 6, 13, 21, 37, 58, 0, 164, 0], "published": "2022-06-13T21:37:58Z", "published_parsed": [2022, 6, 13, 21, 37, 58, 0, 164, 0], "title": "Learning Task-Independent Game State Representations from Unlabeled\n  Images", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=Google&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=2", "value": "Learning Task-Independent Game State Representations from Unlabeled\n  Images"}, "summary": "Self-supervised learning (SSL) techniques have been widely used to learn\ncompact and informative representations from high-dimensional complex data. In\nmany computer vision tasks, such as image classification, such methods achieve\nstate-of-the-art results that surpass supervised learning approaches. In this\npaper, we investigate whether SSL methods can be leveraged for the task of\nlearning accurate state representations of games, and if so, to what extent.\nFor this purpose, we collect game footage frames and corresponding sequences of\ngames' internal state from three different 3D games: VizDoom, the CARLA racing\nsimulator and the Google Research Football Environment. We train an image\nencoder with three widely used SSL algorithms using solely the raw frames, and\nthen attempt to recover the internal state variables from the learned\nrepresentations. Our results across all three games showcase significantly\nhigher correlation between SSL representations and the game's internal state\ncompared to pre-trained baseline models such as ImageNet. Such findings suggest\nthat SSL-based visual encoders can yield general -- not tailored to a specific\ntask -- yet informative game representations solely from game pixel\ninformation. Such representations can, in turn, form the basis for boosting the\nperformance of downstream learning tasks in games, including gameplaying,\ncontent generation and player modeling.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=Google&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=2", "value": "Self-supervised learning (SSL) techniques have been widely used to learn\ncompact and informative representations from high-dimensional complex data. In\nmany computer vision tasks, such as image classification, such methods achieve\nstate-of-the-art results that surpass supervised learning approaches. In this\npaper, we investigate whether SSL methods can be leveraged for the task of\nlearning accurate state representations of games, and if so, to what extent.\nFor this purpose, we collect game footage frames and corresponding sequences of\ngames' internal state from three different 3D games: VizDoom, the CARLA racing\nsimulator and the Google Research Football Environment. We train an image\nencoder with three widely used SSL algorithms using solely the raw frames, and\nthen attempt to recover the internal state variables from the learned\nrepresentations. Our results across all three games showcase significantly\nhigher correlation between SSL representations and the game's internal state\ncompared to pre-trained baseline models such as ImageNet. Such findings suggest\nthat SSL-based visual encoders can yield general -- not tailored to a specific\ntask -- yet informative game representations solely from game pixel\ninformation. Such representations can, in turn, form the basis for boosting the\nperformance of downstream learning tasks in games, including gameplaying,\ncontent generation and player modeling."}, "authors": [{"name": "Chintan Trivedi"}, {"name": "Konstantinos Makantasis"}, {"name": "Antonios Liapis"}, {"name": "Georgios N. Yannakakis"}], "author_detail": {"name": "Georgios N. Yannakakis"}, "author": "Georgios N. Yannakakis", "arxiv_comment": "Conference on Games (CoG) 2022", "links": [{"href": "http://arxiv.org/abs/2206.06490v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2206.06490v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}
